# -*- coding: utf-8 -*-
"""botorch_v4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_tU0saejotJdVItGhEiHTV2QjAvIk-aF
"""
# ¡ifull code for running on cluster¡j
# ------------set your parameters-------------------------------------------

POROSITY = 0.15
N_RUNS = 0         # how many iterations for Bayesian Opt. (will be specified in commandline input)
SEEDS_AMOUNT = 30   # Run how many seeds for the new candidate h
RESOLUTION = 600   # set resolution in Moose

#--------------------feed initial data into botorch--------------------------
import os

# Define the input file path
input_file_path = "/home/htli/pipeline/botorch/initial_dataset/30_seeds.txt"

# Extract the directory path and file name from the input file path
directory, input_file_name = os.path.split(input_file_path)

# Create the output file path by adding 'filtered_' as a prefix to the input file name
output_file_name = "filtered_" + input_file_name
output_file_path = os.path.join(directory, output_file_name)

# Open the input file for reading and create the output file for writing
with open(input_file_path, 'r') as input_file, open(output_file_path, 'w') as output_file:
    # Iterate through the lines in the input file
    for line in input_file:
        # Check if the line contains a valid second value
        if ',' in line and line.split(',')[1]:
            # If the line has a valid second value, write it to the output file
            output_file.write(line)
            
#-----------clean the data and store them as h and VM stress------------------
import numpy as np

# Read the text file
with open(output_file_path, "r") as file:
    lines = file.readlines()

# Initialize lists to store h and VM stress values
h_values = []
VM_stress_values = []

# Iterate through the lines and extract the data
for line in lines:
    parts = line.strip().split(",")
    if len(parts) == 3:
        resolution, VM_str, h_str = parts
        h = float(h_str.split("_")[1][1:])  # Extract the h value

        #VM_stress = VM_str
        VM_stress = float(VM_str)*(-1)
        h_values.append(h)
        VM_stress_values.append(VM_stress)

status = input('-------Choose the mode of operation, 1 - All Data, 2 - Median Value, 3 -  Mean Value, 4 - Variable Data :)----------')
print("----Status----",status)
# Convert the lists to NumPy arrays


def modeselect(status):
	match status:
		case "1":
			print('------All Data Mode Selected!------')		
			VM = np.array(VM_stress_values)
			h = np.array(h_values)
			return VM,h


		case "2":
			print('------Median Mode Selected!------')
			
			h = np.array(h_values)
			VM = np.array(VM_stress_values)
		# Find unique h values
			unique_h_values = np.unique(h)

		# Lists to store unique h values and corresponding median VM values
			unique_h_list = []
			median_vm_list = []

		# Calculate median for each unique h value and append to the lists
			for unique_h in unique_h_values:
				indices = np.where(h == unique_h)
				vm_values = VM[indices]
				median_vm = np.median(vm_values)
				unique_h_list.append(unique_h)
				median_vm_list.append(median_vm)

		# Convert lists to numpy arrays
			h = np.array(unique_h_list)
			VM = np.array(median_vm_list)
			return VM,h

		case "3":
			print('------Mean Mode Selected!------')
			
			h = np.array(h_values)
			VM = np.array(VM_stress_values)
		# Find unique h values
			unique_h_values = np.unique(h)

		# Lists to store unique h values and corresponding median VM values
			unique_h_list = []
			mean_vm_list = []

		# Calculate median for each unique h value and append to the lists
			for unique_h in unique_h_values:
				indices = np.where(h == unique_h)
				vm_values = VM[indices]
				mean_vm = np.mean(vm_values)
				unique_h_list.append(unique_h)
				mean_vm_list.append(mean_vm)

		# Convert lists to numpy arrays
			h = np.array(unique_h_list)
			VM = np.array(mean_vm_list)			
			return VM,h

		case "4":
			print('------Variable Data Mode Selected!------')
			upbound = input('------Choose the upper bound (%):)------')
			lowbound = input('------Choose the lower bound (%):)------')
			upbound = float(upbound)
			lowbound = float(lowbound)
			h = np.array(h_values)
			VM = np.array(VM_stress_values)
		# Split VM values into separate arrays based on unique h values
			unique_h_values = np.unique(h)
			h_vm_dict = {h_val: VM[h == h_val] for h_val in unique_h_values}

		# Calculate IQR for each VM array and adjust the length of h values
			adjusted_h_values = []
			adjusted_vm_values = []

			for h_val, vm_values in h_vm_dict.items():
    				qup, qlow = np.percentile(vm_values, [upbound ,lowbound])
    				iqr = qup - qlow
    				lower_bound = qlow - 1.5 * iqr
    				upper_bound = qup + 1.5 * iqr
    
    			# Filter VM values within IQR range
    				filtered_vm_values = vm_values[(vm_values >= lower_bound) & (vm_values <= upper_bound)]
    				adjusted_h_values.extend([h_val] * len(filtered_vm_values))
    				adjusted_vm_values.extend(filtered_vm_values)

			h = np.array(adjusted_h_values)
			VM= np.array(adjusted_vm_values)
			return VM,h
		case default:
			return "something Wrong"



VM,h = modeselect(status)
if status == "4":
	upbound = input('------Choose the upper bound (%):)------')
	lowbound = input('------Choose the lower bound (%):)------')
	upbound = float(upbound)
	lowbound = float(lowbound)
else:
	print('-----Initializing------')
print('------Here is your initial dataset for the model :)------')
print("h =", h)
print("VM =", VM)

print('------Ready to start Bayesian Optimization!------')

N_RUNS = input('------Please Select Number of Bayesian Optimization Iterations!------')
print("------Total Iterations Set TO------ ",N_RUNS)
N_RUNS = int(N_RUNS)

#---------------------data prep.------------------------
import numpy as np
import torch
from scipy.interpolate import interp1d

train_x = torch.tensor(h).unsqueeze(-1)
exact_obj = torch.tensor(VM).unsqueeze(-1)
best_observed_value = exact_obj.min().item()   #.item() => extract actual number from the tensor.

# define input parameters
init_x, init_y, best_init_y = train_x, exact_obj, best_observed_value

# bounds of our problem = range of our input data
bounds = torch.tensor([[2.], [5.]])   # only consider input values within the range [2, 5].

#----------------------------define get_new_candidates function-------------------------------------------------------------------
from botorch import fit_gpytorch_model
from botorch.models import SingleTaskGP
from botorch.acquisition.monte_carlo import qExpectedImprovement
from botorch.optim import optimize_acqf
from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood


# # ## Assemble above cells into a function to return candidates

def get_new_candidates(init_x, init_y, best_init_y, bounds, n_points=1):
    single_model = SingleTaskGP(init_x, init_y)
    mll = ExactMarginalLogLikelihood(single_model.likelihood, single_model)
    fit_gpytorch_model(mll)

    EI = qExpectedImprovement(
        model=single_model,
        best_f=best_init_y
    )

    candidates, _ = optimize_acqf(
        acq_function=EI,
        bounds=bounds,
        q=n_points,
        num_restarts=200,
        raw_samples=512,
        options={"batch_limit":5, "maxiter": 200}
    )

    return candidates, single_model  # the next point we want to evaluate

#---------------------connect botorch with porespy and MOOSE------------------------------------
import subprocess

def run_porespy(heterogeneity, current_seed, porosity, seeds_amount):
    porespy_script = "/home/htli/pipeline/porespy/code_morphometry_v8.py"    
	# Call the script to generate images with the specified heterogeneity values and seeds
    subprocess.run(["python3", porespy_script] + [str(heterogeneity)] + [str(current_seed)] + [str(porosity)] + [str(seeds_amount)])

def run_moose(heterogeneity, resolution, seed, porosity):	
    moose_script = "/home/htli/pipeline/MOOSE/job_mech_hpc27_simple_auto_v4.sh"  # Update with the correct path

    # Generate the image file name based on the specified heterogeneity, seed, and p
    image_file = "n1000_h{:.2f}_p{:.2f}_s{}.png".format(heterogeneity, porosity, seed)

    command = [
        "bash",
        moose_script,
        image_file,       # The image file path is passed as the first argument
        str(resolution),  # Second argument
    ]
    subprocess.run(command)


def read_moose_result(heterogeneity, seed, porosity):
    # Read the MOOSE output file and extract the relevant information
    file_path = "/home/htli/pipeline/MOOSE/simulation_dir/max_VM_stress_results/max_VM_stress_results.txt"  # Replace with the actual file path

    try:
        with open(file_path, 'r') as file:
            lines = file.readlines()

        target_filename = f"n1000_h{heterogeneity:.2f}_p{porosity:.2f}_s{seed}.png" 
        vm_stress = None

        for line in reversed(lines):   # read from the last line
            if target_filename in line:
                parts = line.strip().split(',')
                if len(parts) >= 3 and parts[1] is not None:
                    vm_stress = float(parts[1])*(-1)  # Extract VM stress value
                break

        if vm_stress is not None:
            return vm_stress
        else:
            print(f"VM stress not found for heterogeneity {heterogeneity} and seed {seed}")
            return None
    except FileNotFoundError:
        print(f"File not found at path: {file_path}")
        return None
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

# -------------------Directories where the images are stored----------------------------------------------------------------------------
image_directory_gp = "/home/htli/pipeline/botorch/images_and_gif/gp_model_images"  # Directory for GP model images
image_directory_ac = "/home/htli/pipeline/botorch/images_and_gif/ac_model_images"  # Directory for acquisition function images
output_directory = "/home/htli/pipeline/botorch/images_and_gif/combined_animation"  # Directory for the combined animation (update as needed)

# -------------------Function to plot GP model predictions------------------------------------------------------------------
import os
import glob
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

# Modify the 'plot_gp_model' function to include annotations for all new candidates and results
def plot_gp_model(model, train_x, train_y, new_h_list, new_results_list, title="GP Model", save_image=False, image_name=None):
    model.eval()
    with torch.no_grad():
        # Predict the mean and standard deviation of the GP at test points
        test_x = torch.linspace(bounds[0, 0], bounds[1, 0], 100).unsqueeze(-1)
        posterior = model.posterior(test_x)
        mean = posterior.mean
        std = posterior.variance.sqrt()
        
        test_x = test_x.squeeze().numpy()  # Convert to 1D NumPy array
        mean = mean.squeeze().numpy()  # Convert to 1D NumPy array
        std = std.squeeze().numpy()  # Convert to 1D NumPy array

        # Plot the true function, GP model predictions, and training points
        plt.figure(figsize=(8, 6))
        plt.title(title)
        plt.xlabel("Input (h)")
        plt.ylabel("Output (VM)")
        plt.plot(train_x.numpy(), train_y.numpy()*(-1), "ro", label="Observations")
        plt.plot(test_x, mean*(-1), "b-", label="GP Mean")
        plt.fill_between(test_x, (mean - 1.96 * std)*(-1), (mean + 1.96 * std)*(-1), alpha=0.2, color="blue", label="GP 95% CI")

        new_results_list_inverted = [-1 * x for x in new_results_list]
        # Plot new candidates and results with gre6en color
        plt.plot(new_h_list, new_results_list_inverted, 'go', label="New Candidates and Results")

        plt.ylim(0, 0.06)  # Set the y-axis limits 
        plt.legend()

        if save_image and image_name:
            image_path = os.path.join(image_directory_gp, image_name)
            plt.savefig(image_path)
            plt.close() # Close the figure after saving it  
            
 
                 

# -------------- Function to plot the acquisition function ---------------------------------------------------
def plot_acquisition_function(acquisition_function, bounds, title="Acquisition Function", save_image=False, image_name=None):
    test_x = torch.linspace(bounds[0, 0], bounds[1, 0], 100).unsqueeze(-1)
    # Initialize the list to store acquisition function values for each test point
    acq_values = []

    for point in test_x:
        # Add a batch dimension to the current test point
        point = point.unsqueeze(0)
        
        # Evaluate the acquisition function at the current test point
        acq_value = acquisition_function(point)
        acq_values.append(acq_value.item())
    
    # Convert the list of values to a NumPy array with shape (10, 1)
    acq_values = np.array(acq_values).reshape(-1, 1)

    # Find the index of the maximum acquisition function value
    max_index = np.argmax(acq_values)
    
    plt.figure(figsize=(8, 6))
    plt.title(title)
    plt.xlabel("Input (h)")
    plt.ylabel("Acquisition Function Value")
    plt.plot(test_x, acq_values, "g-", label="Acquisition Function")

    # Highlight the point with the highest acquisition function value using a red star
    plt.plot(test_x[max_index], acq_values[max_index], "r*", markersize=10, label="Max Acq. Value")

    # plt.ylim(0, 0.05)  # Set the y-axis limits 
    plt.legend()
    
    if save_image and image_name:
            image_path = os.path.join(image_directory_ac, image_name)
            plt.savefig(image_path)
            plt.close() # Close the figure after saving it
#----------------------------run iterations of Bayesian Opt.-------------------------------------------------------------------
import csv
import numpy as np

# Define the path to the CSV file
csv_file_path = "/home/htli/pipeline/botorch/optimization_data/optimization_data.csv"

if status == "1":
    # Create or open the CSV file for writing
    with open(csv_file_path, 'w', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)

        # Write the header to the CSV file
        csv_writer.writerow(["Optimization Run", "New Candidate", "Mean Corresponding Result"])
        current_seed = SEEDS_AMOUNT

        for i in range(N_RUNS):
            print(f"----------------------------Nr. of optimization run: {i}----------------------------------")
            new_candidates, single_model = get_new_candidates(init_x=init_x, init_y=init_y, best_init_y=best_init_y, bounds=bounds, n_points=1)
            new_candidates_list = [round(float(value), 2) for value in new_candidates]  # convert from tensor to a list of float
            print(f"New candidates are: {new_candidates_list}")

            new_h_list = []  # List to store new candidates within one iteration
            new_results_list = []    # List to store corresponding results within one iteration

            for candidate_h in new_candidates_list:
                print(f'candidate_h: {candidate_h}')
                # Use the run_moose function to execute MOOSE for each seed
                run_porespy(candidate_h, current_seed, POROSITY, SEEDS_AMOUNT)

                for seed in range(current_seed, current_seed+SEEDS_AMOUNT):  # run SEEDS_AMOUNT=30 seeds for each candidate_h
                    print(f'seed: {seed}')
                    run_moose(candidate_h, RESOLUTION, seed, POROSITY)
                    result = read_moose_result(candidate_h, seed, POROSITY)
                    print(f'result: {result}')

                    if result is not None:
                        # Write the data directly to the CSV file
                        csv_writer.writerow([i, candidate_h, result])

                        new_h_list.append(candidate_h)  # Append the new candidate to the list
                        new_results_list.append(result)         # Append the corresponding result to the list

                        # Concatenate the new candidates and new_results to init_x and init_y
                        init_x = torch.cat([init_x, torch.tensor(candidate_h).view(-1, 1)])
                        init_y = torch.cat([init_y, torch.tensor(result).view(-1, 1)])

                # Plot the GP model at each iteration and save it
                image_name = f"gp_model_iteration_{i}.png"
                plot_gp_model(single_model, init_x, init_y, new_h_list, new_results_list, title=f"GP Model Iteration {i}", save_image=True, image_name=image_name)
    
                # Plot the  AC function at each iteration and save it
                EI = qExpectedImprovement(model=single_model, best_f=best_init_y)
                image_name_ac = f"ac_function_iteration_{i}.png"
                plot_acquisition_function(EI, bounds, title=f"Acquisition Function Iteration {i}", save_image=True, image_name=image_name_ac)

            # update the current_seed, so the seed number won't repeated        
            current_seed += SEEDS_AMOUNT

            best_init_y = init_y.max().item()*(-1)
            best_init_y_index = init_y.argmax().item()
            corresponding_init_x = init_x[best_init_y_index].item()
            

            # Print the result
            print(f"Best point: {best_init_y}, Corresponding h: {corresponding_init_x}")
            best_init_y *= -1
            print('----------------------Complete one iteration yeah!---------------------------------------')


elif status == "2":
    # Create or open the CSV file for writing
    with open(csv_file_path, 'w', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)

        # Write the header to the CSV file
        csv_writer.writerow(["Optimization Run", "New Candidate", "Median Corresponding Result"])
        current_seed = SEEDS_AMOUNT
        for i in range(N_RUNS):
            print(f"----------------------------Nr. of optimization run: {i}----------------------------------")
            new_candidates, single_model = get_new_candidates(init_x=init_x, init_y=init_y, best_init_y=best_init_y, bounds=bounds, n_points=1)
            new_candidates_list = [round(float(value), 2) for value in new_candidates]  # convert from tensor to a list of float
            print(f"New candidates are: {new_candidates_list}")

            new_h_list = []  # List to store new candidates within one iteration
            new_results_list = []    # List to store corresponding results within one iteration

            median_results = []
            for candidate_h in new_candidates_list:
                print(f'candidate_h: {candidate_h}')
                # Use the run_moose function to execute MOOSE for each seed
                run_porespy(candidate_h, current_seed, POROSITY, SEEDS_AMOUNT)

                results = []
                for seed in range(current_seed, current_seed+SEEDS_AMOUNT):  # run SEEDS_AMOUNT=30 seeds for each candidate_h
                    print(f'seed: {seed}')
                    run_moose(candidate_h, RESOLUTION, seed, POROSITY)
                    result = read_moose_result(candidate_h, seed, POROSITY)
                    print(f'result: {result}')

                    if result is not None:
                        results.append(result)

                # Calculate the mean result for the current candidate
                median_result = np.median(results)
                median_results.append(median_result)

                new_h_list.append(candidate_h)  # Append the new candidate to the list
                new_results_list.append(median_result)         # Append the corresponding result to the list


                # Concatenate the new candidate and its mean result to init_x and init_y
                init_x = torch.cat([init_x, torch.tensor(candidate_h).view(-1, 1)])
                init_y = torch.cat([init_y, torch.tensor(median_result).view(-1, 1)])

            # Write the data directly to the CSV file (Optimization Run, New Candidate, Mean Corresponding Result)
            for candidate_h, median_result in zip(new_candidates_list, median_results):
                csv_writer.writerow([i, candidate_h, median_result])
                
                # Plot the GP model at each iteration and save it
                image_name = f"gp_model_iteration_{i}.png"
                plot_gp_model(single_model, init_x, init_y, new_h_list, new_results_list, title=f"GP Model Iteration {i}", save_image=True, image_name=image_name)
    
                # Plot the  AC function at each iteration and save it
                EI = qExpectedImprovement(model=single_model, best_f=best_init_y)
                image_name_ac = f"ac_function_iteration_{i}.png"
                plot_acquisition_function(EI, bounds, title=f"Acquisition Function Iteration {i}", save_image=True, image_name=image_name_ac)
        
            # update the current_seed, so the seed number won't be repeated        
            current_seed += SEEDS_AMOUNT

            best_init_y = init_y.max().item()*(-1)
            best_init_y_index = init_y.argmax().item()
            corresponding_init_x = init_x[best_init_y_index].item()
            

            # Print the result
            print(f"Best point: {best_init_y}, Corresponding h: {corresponding_init_x}")
            best_init_y *= -1
            print('----------------------Complete one iteration yeah!---------------------------------------')

elif status == "3":
    # Create or open the CSV file for writing
    with open(csv_file_path, 'w', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)

        # Write the header to the CSV file
        csv_writer.writerow(["Optimization Run", "New Candidate", "Mean Corresponding Result"])
        current_seed = SEEDS_AMOUNT
        for i in range(N_RUNS):
            print(f"----------------------------Nr. of optimization run: {i}----------------------------------")
            new_candidates, single_model = get_new_candidates(init_x=init_x, init_y=init_y, best_init_y=best_init_y, bounds=bounds, n_points=1)
            new_candidates_list = [round(float(value), 2) for value in new_candidates]  # convert from tensor to a list of float
            print(f"New candidates are: {new_candidates_list}")

            new_h_list = []  # List to store new candidates within one iteration
            new_results_list = []    # List to store corresponding results within one iteration

            mean_results = []
            for candidate_h in new_candidates_list:
                print(f'candidate_h: {candidate_h}')
                # Use the run_moose function to execute MOOSE for each seed
                run_porespy(candidate_h, current_seed, POROSITY, SEEDS_AMOUNT)

                results = []
                for seed in range(current_seed, current_seed+SEEDS_AMOUNT):  # run SEEDS_AMOUNT=30 seeds for each candidate_h
                    print(f'seed: {seed}')
                    run_moose(candidate_h, RESOLUTION, seed, POROSITY)
                    result = read_moose_result(candidate_h, seed, POROSITY)
                    print(f'result: {result}')

                    if result is not None:
                        results.append(result)

                # Calculate the mean result for the current candidate
                mean_result = np.mean(results)
                mean_results.append(mean_result)
                
                new_h_list.append(candidate_h)  # Append the new candidate to the list
                new_results_list.append(mean_result)         # Append the corresponding result to the list

                # Concatenate the new candidate and its mean result to init_x and init_y
                init_x = torch.cat([init_x, torch.tensor(candidate_h).view(-1, 1)])
                init_y = torch.cat([init_y, torch.tensor(mean_result).view(-1, 1)])

            # Write the data directly to the CSV file (Optimization Run, New Candidate, Mean Corresponding Result)
            for candidate_h, mean_result in zip(new_candidates_list, mean_results):
                csv_writer.writerow([i, candidate_h, mean_result])
                
                # Plot the GP model at each iteration and save it
                image_name = f"gp_model_iteration_{i}.png"
                plot_gp_model(single_model, init_x, init_y, new_h_list, new_results_list, title=f"GP Model Iteration {i}", save_image=True, image_name=image_name)
    
                # Plot the  AC function at each iteration and save it
                EI = qExpectedImprovement(model=single_model, best_f=best_init_y)
                image_name_ac = f"ac_function_iteration_{i}.png"
                plot_acquisition_function(EI, bounds, title=f"Acquisition Function Iteration {i}", save_image=True, image_name=image_name_ac)
  
            # update the current_seed, so the seed number won't be repeated        
            current_seed += SEEDS_AMOUNT

            best_init_y = init_y.max().item()*(-1)
            best_init_y_index = init_y.argmax().item()
            corresponding_init_x = init_x[best_init_y_index].item()
            

            # Print the result
            print(f"Best point: {best_init_y}, Corresponding h: {corresponding_init_x}")
            best_init_y *= -1
            print('----------------------Complete one iteration yeah!---------------------------------------')
        
elif status == "4":

    # Create or open the CSV file for writing
    with open(csv_file_path, 'w', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)

        # Write the header to the CSV file
        csv_writer.writerow(["Optimization Run", "New Candidate", "Filtered Result"])

        current_seed = SEEDS_AMOUNT

        for i in range(N_RUNS):
            print(f"----------------------------Nr. of optimization run: {i}----------------------------------")
            new_candidates, single_model = get_new_candidates(init_x=init_x, init_y=init_y, best_init_y=best_init_y, bounds=bounds, n_points=1)
            new_candidates_list = [round(float(value), 2) for value in new_candidates]  # convert from tensor to a list of float
            print(f"New candidates are: {new_candidates_list}")
            
            new_h_list = []  # List to store new candidates within one iteration
            new_results_list = []    # List to store corresponding results within one iteration

            for candidate_h in new_candidates_list:
                print(f'candidate_h: {candidate_h}')
                # Use the run_moose function to execute MOOSE for each seed
                run_porespy(candidate_h, current_seed, POROSITY, SEEDS_AMOUNT)

                results = []

                for seed in range(current_seed, current_seed+SEEDS_AMOUNT):  # run SEEDS_AMOUNT=30 seeds for each candidate_h
                    print(f'seed: {seed}')
                    run_moose(candidate_h, RESOLUTION, seed, POROSITY)
                    result = read_moose_result(candidate_h, seed, POROSITY)
                    print(f'result: {result}')

                    if result is not None:
                        results.append(result)

                # Calculate IQR and filter results within IQR
                if results:
                    qlow, qup = np.percentile(results, lowbound), np.percentile(results, upbound)
                    iqr = qup - qlow
                    lower_bound, upper_bound = qlow - 1.5 * iqr, qup + 1.5 * iqr
                    filtered_results = [result for result in results if lower_bound <= result <= upper_bound]
                    adjusted_candidates = np.full(len(filtered_results), candidate_h)

                    for filtered_result in filtered_results:
                        csv_writer.writerow([i, candidate_h, filtered_result])

                    # Write the data directly to the CSV file
                    #csv_writer.writerow([i, candidate_h, filtered_results])

                    # Concatenate the filtered candidate_h and mean_result to init_x and init_y
                    #init_x = np.concatenate((init_x, np.full(len(filtered_results), candidate_h)))
                    #init_y = np.concatenate((init_y, [filtered_results]))

                    init_x = torch.cat([init_x, torch.tensor(adjusted_candidates).view(-1, 1)])
                    init_y = torch.cat([init_y, torch.tensor(filtered_results).view(-1, 1)])
            
                # Plot the GP model at each iteration and save it
                image_name = f"gp_model_iteration_{i}.png"
                plot_gp_model(single_model, init_x, init_y, new_h_list, new_results_list, title=f"GP Model Iteration {i}", save_image=True, image_name=image_name)
    
                # Plot the  AC function at each iteration and save it
                EI = qExpectedImprovement(model=single_model, best_f=best_init_y)
                image_name_ac = f"ac_function_iteration_{i}.png"
                plot_acquisition_function(EI, bounds, title=f"Acquisition Function Iteration {i}", save_image=True, image_name=image_name_ac)


            # update the current_seed, so the seed number won't be repeated
            current_seed += SEEDS_AMOUNT

            best_init_y = init_y.max().item()*(-1)
            best_init_y_index = init_y.argmax().item()
            corresponding_init_x = init_x[best_init_y_index].item()
            

            # Print the result
            print(f"Best point: {best_init_y}, Corresponding h: {corresponding_init_x}")
            best_init_y *= -1
            print('----------------------Complete one iteration yeah!---------------------------------------')
else:
    print("error")


#----------------make a combined animation of GP model and AC function transformation during Bayesian Opt.------------------------------
from PIL import Image
import glob
import os


# Get a list of image files in both directories
image_files_gp = sorted(glob.glob(os.path.join(image_directory_gp, "gp_model_iteration_*.png")))
image_files_ac = sorted(glob.glob(os.path.join(image_directory_ac, "ac_function_iteration_*.png")))

# Function to update the animation frame with combined images
def update_combined(frame):
    img_gp = Image.open(image_files_gp[frame])
    img_ac = Image.open(image_files_ac[frame])

    # Determine the width and height for the new canvas
    new_width = max(img_gp.width, img_ac.width)
    new_height = img_gp.height + img_ac.height

    # Create a new image with the combined dimensions
    combined_image = Image.new("RGB", (new_width, new_height))

    # Paste GP model image at the top and acquisition function image below it
    combined_image.paste(img_gp, (0, 0))
    combined_image.paste(img_ac, (0, img_gp.height))

    ax.clear()  # Clear the previous content in the axis
    ax.imshow(combined_image)
    ax.axis('off')  # Turn off the axis
    ax.set_title("")  # Set an empty title

# Create a figure and axis for the animation
fig, ax = plt.subplots(dpi=300)  # Set a higher DPI value for better resolution
ax.axis('off')  # Turn off the axis in the initial figure
ax.set_title("")  # Set an empty title in the initial figure
animation = FuncAnimation(fig, update_combined, frames=len(image_files_gp), repeat=False)

# Save the combined animation as a GIF
animation.save(
    os.path.join(output_directory, "combined_animation.gif"),
    writer='pillow',
    fps=1  # Adjust the frames per second as needed
)
